# Databricks Certified Associate Developer for Apache Spark - Practice Tests

This folder contains practice tests and exercises from the [Udemy course: Databricks Certified Associate Developer for Apache Spark](https://www.udemy.com/topic/databricks-certified-associate-developer-for-apache-spark/?srsltid=AfmBOoo4S31eaguSmN25vgbv8EoHJXznBm4cuUBWaOtwlFYK3-5p-gb9).

## Overview

These are hands-on practice problems designed to help you prepare for the Databricks Certified Associate Developer for Apache Spark certification exam. Each file contains a specific problem focusing on different aspects of Apache Spark DataFrame operations using PySpark.

## File Structure

All files are Databricks notebook files (`.py` format) that can be run in Databricks or converted to standard Python scripts. Each file is numbered sequentially and focuses on a specific Spark DataFrame operation or concept.

## Practice Problems

1. **01_get_list_of_beginner_courses.py** - Filter and sort courses by level and ratings
2. **02_sort_data_by_scheduled_dates.py** - Composite sorting by date and name
3. **03_aggregations_on_array_type_column_in_spark_data_frame.py** - Working with array columns and aggregations
4. **04_sort_courses_by_enrollments.py** - Sorting data by numeric columns
5. **05_get_number_of_courses_for_a_level.py** - Counting and filtering by level
6. **06_get_unique_programming_languages.py** - Extracting unique values
7. **07_filter_mobiles_by_ram_and_storage.py** - Filtering with multiple conditions
8. **08_get_number_of_companies_per_sector.py** - Grouping and counting
9. **09_get_revenue_per_purchase.py** - Calculating aggregations
10. **10_cleanup_keys_for_mobile_details.py** - Data cleaning and transformation
11. **11_get_top_student_by_total_score.py** - Ranking and top-N queries
12. **12_sort_courses_by_level_and_enrollments.py** - Multi-column sorting
13. **13_filter_companies_by_sector_and_dividend.py** - Complex filtering conditions
14. **14_get_list_of_companies_per_sector.py** - Grouping and collecting lists
15. **15_apply_schema_to_companies_data.py** - Schema definition and application
16. **16_get_student_total_score.py** - Aggregation functions
17. **17_get_all_unique_reasons.py** - Working with nested data structures
18. **18_get_top_companies_by_stock_price.py** - Sorting and limiting results
19. **19_advanced_sort_courses_by_level_and_ratings.py** - Advanced sorting techniques
20. **20_get_count_of_companies_by_dividend_status.py** - Conditional aggregations
21. **21_apply_schema_to_bike_details.py** - Schema application with complex types
22. **22_create_data_frame_using_header_and_inferring_schema.py** - Reading data with schema inference

## Topics Covered

- **DataFrame Operations**: Filtering, sorting, selecting columns
- **Aggregations**: Count, sum, average, grouping operations
- **Data Types**: Working with arrays, strings, numeric types
- **Schema Management**: Defining and applying schemas
- **Data Cleaning**: Transforming and cleaning data
- **Complex Queries**: Multi-column sorting, conditional filtering
- **File I/O**: Reading data from files with schema inference

## Usage

### In Databricks

1. Upload these files to your Databricks workspace
2. Open them as Databricks notebooks
3. Run the cells to execute the practice problems

## Prerequisites

- Basic understanding of Python
- Familiarity with Apache Spark concepts
- PySpark library installed (for local execution)
- Databricks account (for running as notebooks)

## Course Information

These practice tests are part of the Udemy course: **Databricks Certified Associate Developer for Apache Spark**

Course Link: https://www.udemy.com/topic/databricks-certified-associate-developer-for-apache-spark/

## Notes

- Each file is self-contained with sample data and problem description
- Files follow Databricks notebook format with markdown cells for documentation
- Solutions are included in each file

---

